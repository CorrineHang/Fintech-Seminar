{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timezone,timedelta\n",
    "import sys\n",
    "import tweepy\n",
    "import re\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import tweepy\n",
    "import jsonpickle\n",
    "import twitter\n",
    "\n",
    "#!!!USER SPECIFIC\n",
    "CONSUMER_KEY = ''\n",
    "CONSUMER_SECRET = '' \n",
    "ACCESS_TOKEN = '' \n",
    "ACCESS_TOKEN_SECRET = ''  \n",
    "\n",
    "#output folder-user-specific\n",
    "output_folder = 'Seminar/'\n",
    "\n",
    "##########\n",
    "\n",
    "#Pass our consumer key and consumer secret to Tweepy's user authentication handler\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "#Pass our access token and access secret to Tweepy's user authentication handler\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# Prep for getting tweets from the US\n",
    "api = tweepy.API(auth)\n",
    "places = api.geo_search(query=\"USA\", granularity=\"country\")\n",
    "place_id = places[0].id\n",
    "print('USA id is: ',place_id)\n",
    "\n",
    "#Switching to application authentication to get 450 tweets every 15 min (user-authentication allows 180)\n",
    "auth = tweepy.AppAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "if (not api):\n",
    "    print (\"Problem Connecting to API\") #error handling\n",
    "api.rate_limit_status()['resources']['search'] # Check how many queries you have left \n",
    "\n",
    "# Define what we search for (hashtags and phrases)\n",
    "#searchQuery = 'place:96683cc9126741d1 #Pepsi OR #Coca-Cola OR' \\\n",
    "              #'\"Pepsi\" OR \"Coca-Cola\"'\n",
    "searchQuery = 'place:96683cc9126741d1 #Bitcoin OR #BTC OR' \\\n",
    "              '\"Bitcoin\" OR \"BTC\"'\n",
    "maxTweets = 5000 # Max number of tweets to collect \n",
    "tweetsPerQry = 100  # The Search API allows up to 100 tweets per query \n",
    "\n",
    "tweetCount = 0\n",
    "\n",
    "# Open a text file to save the tweets to in JSON format\n",
    "with open(output_folder + 'tweets_Histric_Data.json', 'w') as f:\n",
    "\n",
    "    for tweet in tweepy.Cursor(api.search,q=searchQuery).items(maxTweets) :         \n",
    "\n",
    "        #Verify the tweet has place info before writing (It should, if it got past our place filter)\n",
    "        if tweet.place is not None:\n",
    "            if tweet.created_at >= beginday_datetime_utc and tweet.created_at <= endday_datetime_utc :\n",
    "            \n",
    "            #Write the JSON format to the text file, and add one to the number of tweets we've collected\n",
    "                f.write(jsonpickle.encode(tweet._json, unpicklable=False) + '\\n')\n",
    "                tweetCount += 1\n",
    "\n",
    "    #Display how many tweets we have collected\n",
    "    print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "\n",
    "# have a look at the data        \n",
    "tweet._json\n",
    "\n",
    "#A function to clean up and print all of the JSON attributes \n",
    "def PrintMembers(obj):\n",
    "    for attribute in dir(obj):\n",
    "        #We don't want to show built in methods of the class\n",
    "        if not attribute.startswith('__'):\n",
    "            print(attribute)\n",
    "            \n",
    "PrintMembers(tweet)\n",
    "PrintMembers(tweet.place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(r'~/Seminar/tweets_Histric_Data.json')\n",
    "import json\n",
    "data = []\n",
    "with open('/Users/candice/Desktop/Seminar/tweets_Histric_Data.json', errors='ignore') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data)[['created_at','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(post, \n",
    "                                    threshold = 0.1,\n",
    "                                    verbose = False):\n",
    "    \n",
    "    #pre-process text\n",
    "    post = normalize_accented_characters(post)\n",
    "    post = html_parser.unescape(post)\n",
    "    post = strip_html(post)\n",
    "    \n",
    "    #analyze the sentiment for posts\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    #get binary sentiment\n",
    "    binary_sentiment = 'positive' if scores['compound'] >= threshold\\\n",
    "                                   else 'negative'\n",
    "    \n",
    "    if verbose:\n",
    "        \n",
    "        #display sentiment \n",
    "        sentiment_frame = pd.DataFrame([[binary_sentiment, round(scores['compound'], 2)]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Binary Sentiment ', 'Polarity Score']], \n",
    "                                                              labels=[[0,0],[0,1]]))\n",
    "        print(sentiment_frame.to_string(index=False))\n",
    "    \n",
    "    return binary_sentiment,scores['compound']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beginday = \"2018-01-01\"\n",
    "endday = \"2018-01-31\"\n",
    "beginday_datetime_string = beginday + \" 00:00:00\" \n",
    "endday_datetime_string = endday + \" 23:59:59\"  \n",
    "outputFile_name0 = beginday + \"-\" + endday  \n",
    "outputFile_name1 = \".js\"  \n",
    "outputFile_name = outputFile_name0 + outputFile_name1\n",
    "\n",
    "beginday_datetime = datetime.strptime(beginday_datetime_string,'%Y-%m-%d %H:%M:%S')\n",
    "endday_datetime = datetime.strptime(endday_datetime_string,'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "beginday_datetime_beijing = beginday_datetime.replace(tzinfo=timezone(timedelta(hours=8)))\n",
    "endday_datetime_beijing = endday_datetime.replace(tzinfo=timezone(timedelta(hours=8))) \n",
    "beginday_datetime_utc = beginday_datetime_beijing.astimezone(timezone.utc) \n",
    "endday_datetime_utc = endday_datetime_beijing.astimezone(timezone.utc) \n",
    "beginday_datetime_utc = beginday_datetime_utc.replace(tzinfo=None) \n",
    "endday_datetime_utc = endday_datetime_utc.replace(tzinfo=None) \n",
    "\n",
    "consumer_key = ''\n",
    "consumer_secret = '' \n",
    "access_token = '' \n",
    "access_secret = ''  \n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    " \n",
    "api = tweepy.API(auth)\n",
    "\n",
    "searchQuery = 'place:96683cc9126741d1 #Bitcoin OR #BTC OR' \\\n",
    "              '\"Bitcoin\" OR \"BTC\"'\n",
    "tweets = []\n",
    "\n",
    "for tweet in tweepy.Cursor(api.user_timeline,q=searchQuery,tweet_mode=\"extended\").items():\n",
    "    if tweet.created_at >= beginday_datetime_utc and tweet.created_at <= endday_datetime_utc :\n",
    "        tweets.append(tweet._json)\n",
    "\n",
    "with open(outputFile_name,'w') as outputFile:\n",
    "        print(\"Grailbird.data.tweets_{0} =\".format(outputFile_name0),file = outputFile)\n",
    "        tweets_output = json.dumps(tweets, sort_keys=True, indent=4, separators=(',', ':'))\n",
    "        tweets_output = re.sub('\"full_text\":\"','\"text\":\"',tweets_output) \n",
    "        print(tweets_output,file = outputFile)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
